# .env Datei im Verzeichnis .allmystery/

# --- Generelle Konfiguration ---

# Welcher LLM-Provider soll verwendet werden? Optionen: "gemini" oder "ollama"
LLM_PROVIDER="gemini"

# Welches spezifische Modell soll verwendet werden?
# Beispiele Gemini: gemini-1.5-pro-latest, gemini-1.5-flash-latest
# Beispiele Ollama: llama3:8b, mistral:7b, gemma2:9b (siehe 'ollama list')
MODEL_NAME="gemini-1.5-pro-latest"


# --- Gemini spezifische Konfiguration (nur nötig wenn LLM_PROVIDER="gemini") ---
# Ersetzen Sie 'DEIN_API_SCHLUESSEL' durch Ihren tatsächlichen Google AI API Key
GEMINI_API_KEY="DEIN_API_SCHLUESSEL"


# --- Ollama spezifische Konfiguration (nur nötig wenn LLM_PROVIDER="ollama") ---
# Die URL, unter der Ihr Ollama-Server läuft (Standard ist oft ok)
OLLAMA_BASE_URL="http://localhost:11434"